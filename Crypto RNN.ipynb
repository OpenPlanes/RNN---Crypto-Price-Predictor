{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "41dd5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "#importing tensorflow stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dd22fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        low       high       open      close      volume\n",
      "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
      "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
      "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
      "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n",
      "4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('crypto_data/LTC-USD.csv',names=['time','low','high','open','close','volume'])\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7cc9f57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ETH-USD_close  future\n",
      "time                             \n",
      "1528968660            NaN   486.0\n",
      "1528968720      486.01001   486.0\n",
      "1528968780      486.00000   486.0\n",
      "1528968840      485.75000   486.0\n",
      "1528968900      486.00000   486.0\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 10 #predicting 3 minutes ahead\n",
    "RATIO_TO_PREDICT = 'ETH-USD'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Classify function\n",
    "def classify(current,future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#pre process function\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future',1)\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sequential_data=[]\n",
    "    prev_days = deque(maxlen = SEQ_LEN)\n",
    "    #what the above function does\n",
    "    #it first makes a sequence of 60 as stated above, then as new values come in older values will pop out\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days),i[-1]])\n",
    "    random.shuffle(sequential_data)\n",
    "    #balancing data\n",
    "    buys = []\n",
    "    sells = []\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq,target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq,target])\n",
    "    \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys),len(sells))\n",
    "    \n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    \n",
    "    sequential_data = buys+sells\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X),y\n",
    "    \n",
    "    \n",
    "    \n",
    "#Making a dataset easier to read\n",
    "main_df = pd.DataFrame()\n",
    "ratios = ['BTC-USD','LTC-USD','ETH-USD','BCH-USD']\n",
    "for ratio in ratios:\n",
    "    dataset=f'crypto_data/{ratio}.csv'\n",
    "    df = pd.read_csv(dataset,names=['time','low','high','open','close','volume'])\n",
    "    #print(df.head(5))\n",
    "    df.rename(columns = {'close':f'{ratio}_close','volume':f'{ratio}_volume'},inplace=True)\n",
    "    df.set_index('time',inplace=True)\n",
    "    df = df[[f'{ratio}_close',f'{ratio}_volume']]\n",
    "    #print(df.head(5))\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "        \n",
    "        \n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "print(main_df[[f'{RATIO_TO_PREDICT}_close','future']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c44a133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ETH-USD_close     future  target\n",
      "time                                        \n",
      "1528968660            NaN  485.75000       0\n",
      "1528968720      486.01001  486.00000       0\n",
      "1528968780      486.00000  486.00000       0\n",
      "1528968840      485.75000  485.98999       1\n",
      "1528968900      486.00000  485.98999       0\n",
      "1528968960      486.00000  485.98999       0\n",
      "1528969020      485.98999  485.98999       0\n",
      "1528969080      485.98999  486.00000       1\n",
      "1528969140      485.98999  486.00000       1\n",
      "1528969200      485.98999  486.00000       1\n"
     ]
    }
   ],
   "source": [
    "main_df['target'] = list(map(classify,main_df[f'{RATIO_TO_PREDICT}_close'],main_df['future']))\n",
    "print(main_df[[f'{RATIO_TO_PREDICT}_close','future','target']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b0fac35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify function works!\n",
    "#next step\n",
    "#build sequences\n",
    "#balance data\n",
    "#normalize data\n",
    "#scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "69d14b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "#print(last_5pct) #looking to split validation data and training data\n",
    "#now going to split training data and validation data\n",
    "\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "main_df = main_df[(main_df.index < last_5pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "257292f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sungmin\\AppData\\Local\\Temp\\ipykernel_8616\\1955801631.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('future',1)\n",
      "C:\\Users\\Sungmin\\AppData\\Local\\Temp\\ipykernel_8616\\1955801631.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df = df.drop('future',1)\n"
     ]
    }
   ],
   "source": [
    "#preprocess_df(main_df)\n",
    "train_x,train_y = preprocess_df(main_df)\n",
    "validation_x,validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "validation_x = np.asarray(validation_x)\n",
    "validation_y = np.asarray(validation_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bf0f0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001,decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ff9a57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
    "filepath = 'RNN_Final-{epoch:02d}-{val_acc:.3f}'\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a36e3da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1159/1160 [============================>.] - ETA: 0s - loss: 0.7045 - accuracy: 0.5279"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Failed to format this callback filepath: \"models/RNN_Final-{epoch:02d}-{val_acc:.3f}.model\". Reason: \\'val_acc\\''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8616\\4258216349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[1;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[0;32m   1485\u001b[0m             epoch=epoch + 1, batch=batch + 1, **logs)\n\u001b[0;32m   1486\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m       raise KeyError(\n\u001b[0m\u001b[0;32m   1488\u001b[0m           \u001b[1;34mf'Failed to format this callback filepath: \"{self.filepath}\". '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m           f'Reason: {e}')\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Failed to format this callback filepath: \"models/RNN_Final-{epoch:02d}-{val_acc:.3f}.model\". Reason: \\'val_acc\\''"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57283fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd68eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
